# Mass Spectrometry Analysis Pipeline Modularization Guide

## Project Overview

Refactor `CleanCode.R` (3322 lines) into 14 independently debuggable modules so that the mass spectrometry data analysis workflow can be executed step by step.

**Key features:**
- Modules exchange data by saving and loading `RData` files
- Each module can be debugged in isolation
- All analytical details from the original code are preserved

## Directory Layout

```
CodeNorm/
├── main_pipeline.R          # main orchestrator script
├── guide.md                 # this document
├── CleanCode.R              # original script (reference)
├── Module/                  # modular code
│   ├── module01_setup.R
│   ├── module02_data_import.R
│   └── ...
├── Dev/                     # debugging scripts
├── Output/                  # result exports
├── Reference/               # annotation files (required)
├── Rawdata/                 # raw inputs (required)
└── *.RData                  # data passed between modules
```


## Module List

### Module 1: Environment initialization ✓

**File:** `Module/module01_setup.R`

**Responsibilities:**
1. Verify that required directories (`Reference`, `Rawdata`) exist; abort with an error if missing
2. Automatically create optional directories (`Output`, `Module`, `Dev`)
3. Save configuration variables into an `RData` file

**Inputs:**
- `dir_config` — list of directory paths

**Outputs:**
- `Module01_workspace.RData` — all environment variables saved in the working directory
  - Contains: `dir_config`, `config`

**Function signature:**
```r
module01_setup(dir_config)
```

**Usage example:**
```r
# from main_pipeline.R
source(file.path(dir_config$module, "module01_setup.R"))
module01_setup(dir_config)
load("Module01_workspace.RData")
```

**Tests:**
1. Ensure `Reference/` and `Rawdata/` are present
2. Run the Module 1 section of `main_pipeline.R`
3. Confirm that `Module01_workspace.RData` is created
4. Confirm that `Output/`, `Module/`, and `Dev/` directories are created

**Notes:**
- `Reference` and `Rawdata` are mandatory; missing ones raise an error
- Other directories are auto-created

---

**The following modules are pending and will be added after user confirmation.**

### Module 2: Data import & grouping table ✓

**File:** `Module/module02_data_import.R`

**Responsibilities:**
1. Read TSV data files (pattern matching supported)
2. Automatically clean column names (remove shared prefixes)
3. Generate a `sampleGroup` template that highlights every available option
4. Read the user-completed `sampleGroup`
5. Generate `FinalName` values and rename the expression columns

**Inputs:**
- `Module01_workspace.RData` — workspace variables from Module 1 (loaded via `load`)
- TSV data files located inside `Rawdata/`
- A user-edited `Module02_sampleGroup_template.csv`

**Outputs:**
- `Module02_sampleGroup_template.csv` — template generated for the user to edit (saved in the working directory)
- `Module02_sampleGroup.csv` — validated grouping information generated by the pipeline
- `Module02_workspace.RData` — workspace variables now include loaded data
  - Contains: everything from Module 1 plus `data_raw` and `sampleGroup`
- `Output/Module02_data_raw.csv` — CSV export of the raw data

**Core functions:**
```r
# Step 1: load data and generate template
result <- module02_read_and_generate_template(dir_config, file_pattern = "_matrix.*\.tsv$")

# Step 2: wait for the user to fill Module02_sampleGroup_template.csv

# Step 3: validate the template and create Module02_sampleGroup.csv
result <- module02_process_samplegroup(dir_config, result$data)
```

**sampleGroup table columns:**
- `OriginalName`: cleaned original column name
- `bioGroup`: biological group label (required)
- `CatalyticGroup`: `Cata` or `NoCat` (template fills example values such as `Cata/Cata/NoCat/NoCat`)
- `PLtype`: `Light`, `H2O2`, or `PL` (template already contains example values)
- `Context`: `Experiment`, `Control`, or `Spatial` (example values pre-filled)
- `replicate`: `1/2/3` (cycle repeats in the template)
- `FirstROCgroup`: `A/B/C/A&B/NA` (example values provided)
- `SecondROCgroup`: `A/B/C/D/E/F` (example values provided)
- `Order`: integer (1,2,3...) controlling column display order; default is 1,2,3...
- `FinalName`: auto-generated as `bioGroup_LFQ_replicate`

**Template guidance:**
- All possible enum values appear at least once
- Options are evenly distributed (e.g., for 10 samples: `A/A/A/A/B/B/B/C/C/C`)
- `replicate` cycles through 1/2/3
- `Order` defaults to 1,2,3 in the original sample order

**Order column notes:**
- Modify `Order` to control how columns are arranged
- Data flow: sort by `Order` → reorder columns → rename using `FinalName`
- Columns with `Order = 1` appear first, then `Order = 2`, etc.
- The `Gene` column always stays in the first position

**Workflow:**
1. Run the Module 2 portion of `main_pipeline.R`
2. Open the generated `Module02_sampleGroup_template.csv`
3. Fill in all required values (use provided hints; `bioGroup` is mandatory)
4. Optionally adjust `Order` locations if you want to reshuffle columns
5. Save `Module02_sampleGroup_template.csv` (no need to save as a new file)
6. Press Enter to continue; the script will validate the template and emit `Module02_sampleGroup.csv`

**Tests:**
1. Ensure a TSV file exists inside `Rawdata/`
2. Run Module 2 Step 1 and verify `Module02_sampleGroup_template.csv` is created
3. Fill in the template (you can test by setting column 5 to `Order = 1`)
4. Save the template and press Enter
5. The pipeline automatically validates and writes `Module02_sampleGroup.csv`
6. Confirm that columns have been reordered according to `Order`
7. Check that `Module02_workspace.RData` exists
8. Verify that column names are renamed to the `FinalName` pattern

**Configuration tips:**
- Update `data_config$file_pattern` in `main_pipeline.R` to change the match pattern
- Default: `"_matrix.*\.tsv$"` matches TSV files containing `_matrix`

**Notes:**
- The template includes intelligently filled example values, so you can edit where needed
- `FinalName` is auto-generated; leave it blank in the template
- `bioGroup` and `Order` are required fields; missing values cause errors
- `Order` must be an integer and controls the display sequence
- Data is reordered by `Order` before columns are renamed via `FinalName`
- Workflow: user edits the template → save → pipeline validates → `Module02_sampleGroup.csv` is generated
- Output files are prefixed with `Module02_`
- `RData` files stay in the working directory; CSVs appear in `Output/`

---

### Module 3: Annotation system ✓

**File:** `Module/module03_annotation.R`

**Responsibilities:**
1. Load the HPA database to generate `Cytosol`, `Nuclear`, and `Nuclear_Cytosol` annotations
2. Load MitoCarta data to mark mitochondrial proteins
3. Read SG reference datasets (`GO_SGs`, `HaloMap_SGs`, `HaloMap_DifMethods`)
4. Apply multiple annotation schemes (default: `HaloMap_Localization`, `GO_Localization`, `MultiBait_Localization`)
5. Support user-defined custom annotations

**Inputs:**
- `Module02_workspace.RData` — carries everything needed from Modules 1–2, including `data_raw` and `sampleGroup`
- Annotation files inside `Reference/`:
  - `proteinatlas.tsv` — HPA database
  - `MitoCarta3.0.csv` — mitochondrial proteins
  - `CytoSGs GO.tsv` — GO-based SG annotations
  - `HaloMap SGs reference.csv` — HaloMap SG reference set
  - `HaloMap differentMethods SGs.csv` — SGs from different HaloMap workflows

**Outputs:**
- `Module03_workspace.RData` — workspace variables now include `data_annotated` and `annotation_references`
- `Output/Module03_data_annotated.csv` — CSV export of the annotated matrix

**Core functions:**
```r
# load annotation references
HPA_anno <- load_HPA_annotations(dir_config)
MitoCarta_anno <- load_MitoCarta_annotations(dir_config)
SGs_refs <- load_SGs_references(dir_config)

# default annotations
module03_annotation(dir_config, data_raw, sampleGroup)

# custom annotations
custom_annotations <- list(
  list(
    column_name = "Custom_Localization",
    TP_source = "GO_SGs",
    TP_column = "Gene",
    TP_label = "SGs"
  )
)
module03_annotation(dir_config, data_raw, sampleGroup, custom_annotations)
```

**Annotation priority:**
1. True positives defined by the user (e.g., SGs)
2. HPA-based `Nuclear`, `Cytosol`, `Nuclear_Cytosol`
3. Mitochondrial proteins (MitoCarta)
4. `Other` for unannotated proteins

**HPA rules:**
- **Cytosol**: must include keywords like `yto`, `crotubule`, `ctin` but exclude `ucleol`, `ucleoplasm`, `uclear`, `itochond`
- **Nuclear**: must include `ucleol`, `ucleoplasm`, or `uclear` but exclude cytosol and other organelle features
- **Nuclear_Cytosol**: contains both cytosol and nuclear attributes while excluding mitochondria

**Default annotation columns:**
- `HaloMap_Localization`: uses HaloMap SG reference as the TP set
- `GO_Localization`: uses GO-based SG annotations as the TP set
- `MultiBait_Localization`: uses HaloMap different-method SGs as the TP set

**Tests:**
1. Ensure `Reference/` contains every required annotation file
2. Run Module 3
3. Confirm `Module03_workspace.RData` is created
4. Verify the annotation columns (`HaloMap_Localization`, `GO_Localization`, `MultiBait_Localization`) are added
5. Check protein counts per annotation category
6. Confirm `Output/Module03_data_annotated.csv` exists

**Notes:**
- HPA entries marked as `Reliability = "Uncertain"` are filtered out
- Overlaps between annotation categories are resolved by priority order
- Custom annotations append after the defaults
- Output files are prefixed with `Module03_`

---

### Module 4: Data standardization ✓

**File:** `Module/module04_standardization.R`

**Responsibilities:**
1. Apply log2 transformation to the expression data
2. Execute global normalization options:
   - `Global_QNorm`: quantile normalization across all samples
   - `Global_MNorm`: median normalization across all samples
3. Execute local normalization within each `bioGroup`:
   - `Local_QNorm`: quantile normalization per group
   - `Local_MNorm`: median normalization per group
4. Produce boxplots that compare the effects of each method, colored by `bioGroup`

**Inputs:**
- `Module03_workspace.RData` — workspace variables from Modules 1–3 (includes `data_annotated`, `sampleGroup`, etc.)
- `norm_types` — vector specifying which normalization variants to compute (configurable)

**Outputs:**
- `Module04_workspace.RData` — workspace now includes `standardized_data_list` and `norm_types_used`
  - Contains: all prior modules plus the normalized data list
- CSV exports in `Output/`:
  - `Module04_log2.csv` — log2-transformed data
  - `Module04_Global_QNorm.csv` — global quantile normalized data
  - `Module04_Global_MNorm.csv` — global median normalized data
  - `Module04_Local_QNorm.csv` — local quantile normalized data
  - `Module04_Local_MNorm.csv` — local median normalized data
- PDF files in `Output/`:
  - `Module04_log2_boxplot.pdf` — log2 boxplot
  - `Module04_Global_Norm_boxplot.pdf` — comparison of global normalizations
  - `Module04_Local_Norm_boxplot.pdf` — comparison of local normalizations
  - `Module04_All_Norm_comparison_boxplot.pdf` — overall comparison of all methods

**Core functions:**
```r
# Use every normalization method
norm_types <- c("noNorm", "Global_QNorm", "Global_MNorm", "Local_QNorm", "Local_MNorm")
result <- module04_standardization(dir_config, data_annotated, sampleGroup, norm_types)

# Only run global normalizations
norm_types <- c("noNorm", "Global_QNorm", "Global_MNorm")
result <- module04_standardization(dir_config, data_annotated, sampleGroup, norm_types)

# Only use median-based normalization
norm_types <- c("noNorm", "Global_MNorm", "Local_MNorm")
result <- module04_standardization(dir_config, data_annotated, sampleGroup, norm_types)
```

**Normalization method descriptions:**

1. `noNorm` (log2 only)
   - Log2 transform the original data
   - No further normalization
   - Used as a baseline to compare other methods

2. `Global_QNorm`
   - Calls `preprocessCore::normalize.quantiles()`
   - Performs quantile normalization across all samples
   - Forces all samples to share the same distribution

3. `Global_MNorm`
   - Computes the median for each sample
   - Normalizes samples by scaling to the global median

4. `Local_QNorm`
   - Groups samples by `sampleGroup$bioGroup`
   - Applies quantile normalization within each group
   - Joins the normalized group matrices afterward

5. `Local_MNorm`
   - Groups samples by `bioGroup`
   - Applies median normalization within each group
   - Merges the results across groups

**Boxplot visualization:**
- Each normalization version produces a before/after boxplot
- Color coding distinguishes different `bioGroup`s
- Color palettes are generated automatically
- Legends identify each `bioGroup`
- Plot titles include the dataset name

**Configuration:**
Set `norm_types` inside `main_pipeline.R`:
```r
# Must include at least one global normalization (QNorm or MNorm)
norm_types <- c("noNorm", "Global_QNorm", "Global_MNorm", "Local_QNorm", "Local_MNorm")
```

**Tests:**
1. Ensure Module 3 has completed and `Module03_workspace.RData` exists
2. Configure the desired `norm_types`
3. Run Module 4
4. Verify that CSV files appear in `Output/` matching the configured normalization types
5. Check that each PDF exists and that their boxplots are colored by `bioGroup`
6. Compare results to see how different normalization methods behave
7. Confirm that `Module04_workspace.RData` is saved
8. Ensure `standardized_data_list` contains every requested variant

**Notes:**
- There must be at least one global normalization (`Global_QNorm` or `Global_MNorm`)
- Requires `preprocessCore`: `BiocManager::install("preprocessCore")`
- Local normalizations rely on `bioGroup` definitions in `sampleGroup`
- Numeric and annotation columns are auto-detected (annotation columns should end with `Localization`)
- Boxplots use `log='y'` scale to visualize distributions more clearly
- Samples that share a `bioGroup` receive the same color palette entry
- Output filenames begin with `Module04_`
- RData files stay in the working directory while CSV/PDF exports go to `Output/`

---

### Module 5: Missing value imputation ✓

**File:** `Module/module05_imputation.R`

**Responsibilities:**
1. Impute missing values using the Perseus strategy (random draws from a normal distribution)
2. Handle group-specific rules for `NoCat` versus `Cat`
3. Adjust behavior based on the number of valid values (`n_valid`)
4. Generate before/after boxplots colored by `bioGroup`

**Inputs:**
- `Module04_workspace.RData` — workspace variables from Modules 1–4 (includes `standardized_data_list`, `sampleGroup`, etc.)
- `impute_cat_mean` — whether to fill `Cat` group entries (default `FALSE`)
- `random_seed` — RNG seed (default `123`)

**Outputs:**
- `Module05_workspace.RData` — workspace now holds `imputed_data_list` and `imputation_params`
  - Contains: the Module 1–4 state plus imputed data
- CSV exports stored in `Output/`:
  - One CSV per normalization version, e.g., `Module05_noNorm_Imputed.csv`, `Module05_Global_QNorm_Imputed.csv`, etc.
- PDF export:
  - `Module05_Imputation_Before_After_boxplot.pdf` — before/after comparison across every dataset

**Core function usage:**
```r
# Default: only impute NoCat, leave Cat as NA
i
impute_cat_mean <- FALSE
random_seed <- 123
result <- module05_imputation(dir_config, standardized_data_list, sampleGroup, 
                              impute_cat_mean, random_seed)

# Enable Cat imputation (means when n_valid == 2)
impute_cat_mean <- TRUE
result <- module05_imputation(dir_config, standardized_data_list, sampleGroup, 
                              impute_cat_mean, random_seed)

# Change the seed for reproducibility
random_seed <- 456
result <- module05_imputation(dir_config, standardized_data_list, sampleGroup, 
                              impute_cat_mean, random_seed)
```

**Imputation strategy details:**

1. Perseus parameters (per sample):
   - `imputation_mean = col_mean - 1.8 * col_sd`
   - `imputation_sd = 0.3 * col_sd`

2. NoCat rules (mandatory):
   - Identify rows where `sampleGroup$CatalyticGroup == "NoCat"`
   - `n_valid == 2`: fill with the average of the two valid values within the same `bioGroup`
   - `n_valid < 2`: draw from `N(imputation_mean, imputation_sd)` using the provided seed

3. Cat rules (optional):
   - Identify rows where `sampleGroup$CatalyticGroup == "Cat"`
   - Default (`impute_cat_mean = FALSE`): keep `NA`
   - When enabled:
     - `n_valid == 2`: fill with the within-group mean
     - `n_valid < 2`: leave `NA`

4. Logic diagram:
```r
for (each bioGroup) {
  if (group == "NoCat") {
    if (n_valid == 2) {
      imputed_value <- mean(valid_values)
    } else if (n_valid < 2) {
      imputed_value <- rnorm(n, imputation_mean, imputation_sd)
    }
  } else if (group == "Cat" && impute_cat_mean == TRUE) {
    if (n_valid == 2) {
      imputed_value <- mean(valid_values)
    }
  }
}
```

**Boxplot characteristics:**
- Each normalization version gets a before/after pair
- Colors differentiate `bioGroup`
- Palettes are generated dynamically
- Legends label the `bioGroup`s
- Titles include the dataset name

**Configuration hints:**
```r
# impute_cat_mean: whether to impute `Cat` entries when `n_valid == 2`
impute_cat_mean <- FALSE  # default: skip Cat imputation

# random_seed: ensures Perseus sampling is reproducible
random_seed <- 123        # change as needed
```

**Tests:**
1. Confirm Module 4 created `Module04_workspace.RData`
2. Set `impute_cat_mean` and `random_seed`
3. Run Module 5
4. Check that every expected CSV appears in `Output/`
5. Inspect the PDF to confirm before/after differences
6. Ensure annotations stay aligned with the original data
7. Confirm `Module05_workspace.RData` exists
8. Verify `imputed_data_list` contains every normalization version
9. Rerun with the same seed to check reproducibility

**Notes:**
- Module 2 must have run previously (for `CatalyticGroup` and `bioGroup` info)
- Module 4 must have run previously (to provide `standardized_data_list`)
- Perseus sampling is stochastic, so `random_seed` keeps it repeatable
- Annotations are not changed by imputation
- Missing values in `NoCat` are always imputed (this is required for downstream steps)
- Imputing `Cat` is optional and controlled via `impute_cat_mean`
- `n_valid` is the number of non-NA samples within a `bioGroup`
- Filename prefix: `Module05_`
- RData files stay in the working directory; CSV/PDF exports go to `Output/`
- Imputed datasets preserve the original matrix shape
- Use `set.seed(random_seed)` to guarantee identical Perseus results

---

### Module 6: Heatmap system ✓

**File:** `Module/module06_heatmap.R`

**Responsibilities:**
1. Correlation heatmaps: analyze sample-to-sample similarity
   - Highly customizable sample selection
   - PLtype × Context annotation combinations
   - Smart color mapping rules
2. Global expression heatmaps (`AllLocalization`): visualize all proteins across samples
3. Localization-specific heatmaps (`by_localization`): plot one heatmap per localization category
4. Support drawing multiple normalized versions in one run

**Inputs:**
- `Module05_workspace.RData` — workspace variables from Modules 1–5 (includes `imputed_data_list`, `sampleGroup`)
- `selected_versions` — versions to plot (e.g., `c("noNorm_Imputed", "Local_QNorm_Imputed")`)
- `heatmap_types` — which heatmap types to render (`all`, `correlation`, `by_localization`)
- `correlation_config` — detailed parameters for correlation heatmaps (see below)
- `localization_columns` — annotation columns to use for localization grouping (`NULL` auto-detects)
- `color_params` — color scale settings for expression heatmaps

**Outputs:**
- `Module06_workspace.RData` — workspace now includes `heatmap_info`
  - Contains data from all prior modules plus heatmap metadata
- PDF files in `Output/`:
  - `Module06_{version}_correlation_heatmap.pdf`
  - `Module06_{version}_AllLocalization_heatmap.pdf`
  - `Module06_{version}_{localization_name}_heatmap.pdf`

**Core functions:**
```r
result <- module06_heatmap(dir_config, imputed_data_list, sampleGroup,
                          selected_versions = c("noNorm_Imputed", "Local_QNorm_Imputed"),
                          heatmap_types = c("all", "correlation", "by_localization"))

correlation_config <- list(
  corr_min = 0.8, corr_max = 1, corr_center = 0.9,
  col_low = "#4D97CD", col_center = "white", col_high = "#DB6968",
  exclude_context = NULL,
  exclude_pltype = NULL,
  exclude_catalytic = NULL,
  include_biogroups = NULL
)
```

**Heatmap types explained:**

1. Correlation heatmap (`correlation`)
   - Shows Pearson correlations between samples
   - Provides fine-grained sample filtering
   - Uses three column annotations (PLtype, Context, Sample_Color)
   - Applies an intelligent color mapping (see below)
   - Supports including/excluding specific sample classes

2. Global expression heatmap (`all`)
   - Displays every protein across all samples
   - Row annotations: all `Localization` columns (e.g., `HaloMap_Localization`)
   - Column annotations: auto-colored `bioGroup`
   - Filters out rows that are entirely `NA`

3. Localization-specific heatmaps (`by_localization`)
   - Produces one heatmap per localization label (SGs, Nuclear, Cytosol, etc.)
   - Each heatmap contains only the proteins assigned to that category
   - Columns annotated by `bioGroup`
   - Filenames follow `Module06_{version}_{localization_name}_heatmap.pdf`

**Correlation heatmap configuration:**

_Sample filtering:_
```r
correlation_config <- list(
  exclude_context = c("Control"),     # keep only Experiment and Spatial
  exclude_pltype = c("PL"),           # drop PL group
  exclude_catalytic = c("NoCat"),      # keep only catalytic groups
  include_biogroups = NULL
)
```
or specify exact `bioGroup`s (takes priority):
```r
correlation_config <- list(
  include_biogroups = c("K69A1B3_Light", "K69C3_Light", "C20_Light")
)
```

**Color mapping rules:**
Column annotations (top to bottom):
1. `PLtype`: Light/H2O2/PL
2. `Context`: Experiment/Control/Spatial
3. `Sample_Color`: color derived from the PLtype × Context pair

`Sample_Color` palette priority (highest first):
1. Spatial (if `bioGroup` contains "Spatial") → **black**
2. Light Experiment → **deep blue (#0066CC)**
3. Light Control → **light blue (#87CEEB)**
4. H2O2 Experiment → **deep orange (#FF8C00)**
5. H2O2 Control → **gold (#FFD700)**
6. PL Experiment → **dark green (#228B22)**
7. PL Control → **light green (#90EE90)**
8. Other Experiment → **dark gray (#696969)**
9. Other Control → **light gray (#D3D3D3)**

**Expression heatmap colors:**
```r
color_params <- list(
  custom_min = -4,
  custom_max = 4,
  custom_center = 0,
  col_low = "#4D97CD",
  col_center = "white",
  col_high = "#DB6968"
)
```

**Examples:**
1. Generate all heatmap types for two versions, excluding `NoCat` samples:
```r
selected_versions <- c("noNorm_Imputed", "Local_QNorm_Imputed")
heatmap_types <- c("all", "correlation", "by_localization")
correlation_config <- list(
  corr_min = 0.8, corr_max = 1, corr_center = 0.9,
  col_low = "#4D97CD", col_center = "white", col_high = "#DB6968",
  exclude_catalytic = c("NoCat")
)
result <- module06_heatmap(dir_config, imputed_data_list, sampleGroup,
                          selected_versions, heatmap_types,
                          correlation_config, NULL, color_params)
```

2. Only plot correlation heatmaps while excluding Control samples:
```r
selected_versions <- c("Local_QNorm_Imputed")
heatmap_types <- c("correlation")
correlation_config <- list(
  corr_min = 0.8, corr_max = 1, corr_center = 0.9,
  exclude_context = c("Control")
)
result <- module06_heatmap(...)
```

3. Only include specific `bioGroup`s:
```r
correlation_config <- list(
  include_biogroups = c("K69A1B3_Light", "K69C3_Light", "K20_Light")
)
```

4. Customize the color scale to a blue-white-red gradient:
```r
color_params <- list(
  custom_min = -3, custom_max = 3, custom_center = 0,
  col_low = "#0000FF",
  col_center = "#FFFFFF",
  col_high = "#FF0000"
)
```

**Tests:**
1. Make sure Module 5 produced `Module05_workspace.RData`
2. Choose at least one `selected_versions`
3. Pick one or more `heatmap_types`
4. Configure `correlation_config` if rendering correlation heatmaps
5. Run Module 6
6. Inspect `Output/` for the expected PDF files
7. Confirm `Module06_workspace.RData` exists
8. Verify that multiple versions produce separate heatmaps

**Technical details:**
- Clustering uses `ward.D2` linkage with correlation distance for all heatmaps
- Rows entirely filled with `NA` are filtered out
- Gene names are hidden to avoid overcrowding
- Column labels are rotated by 45° for readability
- If `localization_columns = NULL`, all columns ending with `Localization` are auto-detected
- Colors for `bioGroup` are generated via `scales::hue_pal()` or `rainbow()`
- `Sample_Color` follows the PLtype × Context mapping shown above
- Expression heatmaps use a user-defined low-center-high gradient

**Configuration snippet (main_pipeline.R):**
```r
selected_versions <- c("noNorm_Imputed", "Local_QNorm_Imputed")
heatmap_types <- c("all", "correlation", "by_localization")
correlation_config <- list(
  corr_min = 0.8, corr_max = 1, corr_center = 0.9,
  col_low = "#4D97CD", col_center = "white", col_high = "#DB6968",
  exclude_catalytic = c("NoCat")
)
localization_columns <- NULL
color_params <- list(...)
```

**Notes:**
- Module 5 must finish first (providing `imputed_data_list`)
- When both `include_biogroups` and exclusion rules are set, `include_biogroups` takes precedence
- Any `bioGroup` containing the word "Spatial" (case-insensitive) is colored black
- Annotation categories like "SGs" are highlighted in the row annotations
- Color priority: Spatial > PLtype×Context > other conditions
- Experiment colors are darker than Control colors
- Requires `pheatmap` and `scales` (`install.packages()`)
- PDF sizes:
  - Correlation heatmaps: 20×18 inches
  - AllLocalization: 28×24 inches
  - Localization-specific: dynamic sizing based on protein count
- Files are prefixed with `Module06_` followed by the version and localization
- RData files remain in the working directory; PDFs go to `Output/`
- Heatmaps are clustered automatically so similar samples cluster together
- Only numerical columns (not annotation columns) are used for correlation

---

### Module 7: First differential analysis ✓

**File:** `Module/module07_diff_analysis1.R`

**Responsibilities:**
1. Automatically construct comparison groups based on `sampleGroup$FirstROCgroup`
2. Perform differential expression analysis with the `limma` package
3. Apply empirical Bayes moderation (`eBayes`)
4. Report logFC and adjusted p-values (FDR)
5. Output combined summary tables, expression matrices, and wide-format logFC tables

**FirstROCgroup logic:**
- Members sharing the same identifier (e.g., `A`, `A/B`, `A&B`) belong to the same group
- Within each group, samples with `Context == "Experiment"` are compared to every `Control`
- Example:
  - Experiment: `K69A1B3_Light` (FirstROCgroup = `A`)
  - Controls: `K69A1B3_noLight`, `A1B3_Light` (FirstROCgroup = `A`), `K69_Light` (FirstROCgroup = `A&B`)
  - Generated comparisons:
    * `K69A1B3_Light` vs `K69A1B3_noLight`
    * `K69A1B3_Light` vs `K69_Light`
    * `K69A1B3_Light` vs `A1B3_Light`

**Inputs:**
- `Module06_workspace.RData` — contains Modules 1–6 outputs, including `imputed_data_list` and `sampleGroup`
- `sampleGroup` must include `FinalName`, `bioGroup`, `FirstROCgroup`, and `Context`
- `selected_versions` – vector specifying which normalized version(s) to analyze (`NULL` means all versions)

**Outputs:**
- `Module07_workspace.RData` — adds `diff_results1`, `comparisons_used`, and `comparison_info`
- `Output/Module07_{version}_DiffAnalysis.csv` — consolidated differential analysis results with logFC and adj.P.Val per comparison
- `Output/Module07_{version}_ExprMatrix.csv` — gene × sample expression matrix
- `Output/Module07_{version}_LogFC_Wide.csv` — logFC wide table
- `Output/Module07_{version}_DiffAnalysis_Full.xlsx` — multi-sheet Excel workbook containing `Combined`, `LogFC_Wide`, `ExprMatrix`, and per-comparison tabs

**Core workflow:**
1. Parse `FirstROCgroup` to identify all ROC groups (A, B, C, etc.)
2. Split composite labels (e.g., `A&B`, `A/B`) into their components
3. Determine which `bioGroup`s act as `Experiment` and `Control` per group
4. Build design matrices via `model.matrix(~ 0 + Group)` with `Group` from `bioGroup`
5. Fit linear models with `limma::lmFit`
6. Create contrast matrices using `limma::makeContrasts`
7. Apply `contrasts.fit()` and `eBayes()`
8. Extract results via `limma::topTable(n = Inf, adjust.method = "BH")`
9. Compile logFC and adjusted p-values into combined CSV, expression matrix, and wide tables

**CSV structure for combined results:**
```
Gene | Comparison1_logFC | Comparison1_adj.P.Val | Comparison2_logFC | Comparison2_adj.P.Val | ... | [annotation columns]
```
**Expression matrix CSV:**
```
Gene | Sample1 | Sample2 | Sample3 | ...
```
**LogFC wide CSV:**
```
Gene | Comparison1 | Comparison2 | Comparison3 | ...
```
**Excel sheets:**
- `Combined`: same as `DiffAnalysis.csv`
- `LogFC_Wide`: logFC wide table
- `ExprMatrix`: expression matrix
- `ComparisonX`: full `topTable` for that comparison (columns: `Gene`, `logFC`, `AveExpr`, `t`, `P.Value`, `adj.P.Val`, `B`)

**Usage examples:**
1. Analyze every version; comparisons are built automatically:
```r
result <- module07_diff_analysis1(dir_config, imputed_data_list, sampleGroup, selected_versions = NULL)
```
2. Limit analysis to specific versions:
```r
selected_versions <- c("noNorm_Imputed", "Local_QNorm_Imputed")
result <- module07_diff_analysis1(dir_config, imputed_data_list, sampleGroup, selected_versions)
```
3. Example `FirstROCgroup` setup:
| bioGroup           | FirstROCgroup | Context     | Description                       |
|--------------------|---------------|-------------|-----------------------------------|
| K69A1B3_Light      | A             | Experiment  | Experimental sample for group A   |
| K69A1B3_noLight    | A             | Control     | Control 1 for group A             |
| A1B3_Light         | A             | Control     | Control 2 for group A             |
| K69_Light          | A&B           | Control     | Control shared by A and B         |
| K69C3_Light        | B             | Experiment  | Experimental sample for group B   |
| K69C3_noLight      | B             | Control     | Control 1 for group B             |
| C3_Light           | B             | Control     | Control 2 for group B             |
| C3_H2O2            | C             | Experiment  | Experimental sample for group C   |
| C3_noH2O2          | C             | Control     | Control for group C               |
| K20_Light          | -             | Spatial     | Spatial control sample (excluded from the first diff analysis)

**Automatically generated comparisons:**
- Group A: `K69A1B3_Light` vs `K69A1B3_noLight`
- Group A: `K69A1B3_Light` vs `A1B3_Light`
- Group A: `K69A1B3_Light` vs `K69_Light`
- Group B: `K69C3_Light` vs `K69C3_noLight`
- Group B: `K69C3_Light` vs `C3_Light`
- Group B: `K69C3_Light` vs `K69_Light`
- Group C: `C3_H2O2` vs `C3_noH2O2`

**Tests:**
1. Make sure Module 5 produced `Module05_workspace.RData` (includes `imputed_data_list`)
2. Ensure `sampleGroup` contains `FinalName`, `bioGroup`, `FirstROCgroup`, and `Context`
3. Validate `FirstROCgroup` assignments (Experiment vs Control, composite labels via `&` or `/`)
4. Configure `selected_versions` (NULL = all versions)
5. Run Module 7
6. Check console logs for detected ROC groups and comparisons
7. Verify files in `Output/`: `DiffAnalysis.csv`, `ExprMatrix.csv`, `LogFC_Wide.csv`, `DiffAnalysis_Full.xlsx`

**Process summary:**
1. Parse `FirstROCgroup`
   - Identify every ROC group (A, B, C, etc.)
   - Split compound labels like `A&B` or `A/B`
   - Find the `Experiment` and `Control` `bioGroup`s for each ROC group
2. Automatically construct comparisons within each group: each `Experiment` sample versus every `Control` sample
3. Prepare the expression matrix:
   - Keep only numeric columns
   - Set row names to gene symbols
   - Match the column order to `sampleGroup`
4. Build the design matrix: `model.matrix(~ 0 + Group)` with `Group` derived from `sampleGroup$bioGroup`
5. Fit linear models with `limma::lmFit(expr_matrix, design)`
6. Define contrasts via `limma::makeContrasts()` (each contrast is `GroupA - GroupB`)
7. Fit contrasts and apply empirical Bayes moderation (`limma::contrasts.fit()` and `limma::eBayes()`)
8. Extract results:
   - `limma::topTable(n = Inf, adjust.method = "BH")`
   - Collect `logFC` and `adj.P.Val`
   - Combine all comparisons into wide and expression matrix tables

**Output formats:**
- Combined CSV: columns for each comparison‟s `logFC` and `adj.P.Val`, plus annotation columns
- Expression matrix CSV: gene names and numeric columns per sample
- LogFC wide CSV: gene names and logFC values per comparison
- Excel workbook (`DiffAnalysis_Full.xlsx`) with:
  - `Combined` sheet (same as the combined CSV)
  - `LogFC_Wide` sheet
  - `ExprMatrix` sheet
  - One sheet per comparison (columns: `Gene`, `logFC`, `AveExpr`, `t`, `P.Value`, `adj.P.Val`, `B`)

**Testing checklist:**
1. Confirm Module 5 generated `Module05_workspace.RData`
2. Ensure `sampleGroup` has these columns: `FinalName`, `bioGroup`, `FirstROCgroup`, `Context`
3. Verify `FirstROCgroup` assignments include both Experiment and Control entries; use `&` or `/` for multi-group labels
4. Set `selected_versions` (NULL = all versions)
5. Run Module 7
6. Review console logs for identified ROC groups and generated comparisons
7. Check `Output/` for the expected files:
   - `*_DiffAnalysis.csv`
   - `*_ExprMatrix.csv`
   - `*_LogFC_Wide.csv`
   - `*_DiffAnalysis_Full.xlsx`
8. Verify `Module07_workspace.RData` exists
9. Inspect `diff_results1` structure:
   ```r
   names(diff_results1)  # should include each analyzed version
   names(diff_results1[[1]])  # should include combined, logfc_wide, expr_matrix, raw_results, comparisons, comparison_info, contrast_names
   ```
10. Inspect `comparison_info` to confirm group assignments for each contrast
11. Count significant proteins (e.g., `adj.P.Val < 0.05` and `|logFC| > 1`)

**Statistical notes:**
- Linear modeling fits one model per protein
- Empirical Bayes shrinks variance estimates using all proteins
- P-values are corrected with Benjamini-Hochberg to control FDR
- `topTable` columns:
  - `logFC`: log2 fold change
  - `AveExpr`: average log2 expression
  - `t`: moderated t statistic
  - `P.Value`: raw p-value
  - `adj.P.Val`: BH-adjusted p-value
  - `B`: log odds that the gene is differentially expressed

**Contrast naming:**
- Format: `GroupA_vs_GroupB`
- Special characters sanitized via `make.names()`
- Positive `logFC` indicates `GroupA` has higher expression than `GroupB`

**Module 7 configuration (in `main_pipeline.R`):**
```r
selected_versions_diff <- c("noNorm_Imputed", "Local_QNorm_Imputed")  # NULL for all versions
```

**Additional notes:**
- Module 2 must run before Module 7 so that `FirstROCgroup` and `Context` exist
- Module 5 must run before Module 7 for `imputed_data_list`
- `Context` must be either `Experiment` or `Control`
- Comparisons always follow `Experiment - Control`
- Required packages: `tidyr`, `limma`, `openxlsx`
- Excel sheet names must be ≤31 characters; longer names are truncated
- Output files are prefixed with `Module07_`
- RData files stay in the working directory; CSV/XLSX go to `Output/`
- Only numeric columns are used for modeling; annotations are preserved separately
- Genes without explicit names fall back to row indices
- Recommended thresholds: `adj.P.Val < 0.05`, `|logFC| > 1`
- Each version produces three CSVs and one XLSX file
- The process fully automates contrast construction from `FirstROCgroup`

---

### Module 8: First ROC analysis

**Responsibilities:**
1. Apply SubMito localization mapping to replace generic `Mitochondrion` annotations with MitoCarta3 sub-localizations (MIM, Matrix, MOM, IMS)
2. Run ROC analysis using logFC values and annotation columns to identify optimal thresholds
3. Export ROC curves and Youden Index plots
4. Save transformed datasets and aggregated ROC data for downstream filtering

**Inputs:**
- `Module07_workspace.RData` — includes everything from Modules 1–7 (`diff_results1`, `annotation_references`, etc.)
- MitoCarta3.0 annotation data (for SubMito mapping)

**Outputs:**
- `Module08_workspace.RData` — now contains `roc_results1`, `roc_thresholds1`, `data_with_submito`, and `expr_fdr_df_list`
- `Output/Module08_{version}_ROC_curves.pdf`
- `Output/Module08_{version}_Youden_Index.pdf`
- `Output/Module08_{version}_ROC_data.xlsx` (multi-sheet)
- `Output/Module08_{version}_data_with_SubMito.csv`
- `Output/Module08_all_thresholds.xlsx`
- `Output/Module08_Expr_FDR_df_list.xlsx` (one sheet per version; feeds into Step 13 A/B filtering; excludes SubMito columns)

**Expr_FDR_df_list construction (matching CleanCode.R lines 1728–1739):**
1. `mydata1`: normalized and imputed expression matrix (equivalent to `expr_matrix`/`mylist2` used for heatmaps)
2. `mydata2`: differential analysis wide table (includes FC/FDR) but only the columns between `Gene` and annotation columns—SubMito columns are excluded
3. Output: left-join `mydata1` (Gene + data columns + original annotations) with the FC/FDR columns from `mydata2`
4. Purpose: serve as the input table for Step 13 A/B background filtering (without SubMito annotations)

**Core functions:**
```r
# SubMito transformation
data_transformed <- apply_submito_transformation(
  data = diff_data,
  mitocarta_anno = mitocarta_anno,
  annotation_columns = NULL,  # automatically detect Localization columns
  enable_submito = TRUE
)

# Perform ROC analysis
gn
roc_analysis <- perform_roc_analysis(
  data = data_transformed,
  logfc_columns = logfc_columns,
  annotation_column = "GO_Localization",
  tp_label = "SGs",
  fp_label = "Matrix",
  direction = "<"
)

# Identify optimal thresholds
thresholds <- calculate_optimal_thresholds(roc_dfs, min_tp = 0.3)

# Full module invocation
result <- module08_roc_analysis1(
  dir_config,
  diff_results1,
  annotation_references,
  selected_versions = c("noNorm_Imputed", "Local_QNorm_Imputed"),
  roc_annotation_column = "GO_Localization",
  tp_label = "SGs",
  fp_label = "Matrix",
  enable_submito = TRUE,
  submito_annotation_columns = NULL,
  min_tp = 0.3
)
```

**SubMito transformation steps:**
1. Extract `Symbol` and `MitoCarta3.0_SubMitoLocalization` from MitoCarta3.0
2. Keep only the four sub-localizations: MIM (inner membrane), Matrix (stroma), MOM (outer membrane), IMS (intermembrane space)
3. Join the sub-localization data to the expression matrix
4. For every localization annotation column: if a gene exists in MitoCarta3.0, replace `"Mitochondrion"` with the sub-localization label
5. Drop helper columns to keep the dataset tidy

**ROC analysis workflow:**
1. Filter to TP (`SGs`) and FP (`Matrix`) samples only
2. Require at least 5 samples in each class; skip comparisons that do not meet this threshold
3. Invoke `pROC` with `levels = c(FP_label, TP_label)` and `direction = "<"` (lower values correspond to FP)
4. Extract ROC metrics:
   - `Threshold`
   - `TP`: true positive rate (sensitivity)
   - `FP`: false positive rate (1 - specificity)
   - `TP_FP`: Youden's Index (`TP - FP`)
5. Determine the optimal threshold:
   - Select rows with the maximum Youden's Index
   - If all candidate rows have `TP < 0.3`, set the threshold to 0 (reject)
   - Otherwise choose the smallest `Threshold` among rows where `TP >= 0.3`

**ROC curve plots:**
- X-axis: False Positive Rate (FPR)
- Y-axis: True Positive Rate (TPR)
- AUC: area under the curve (higher is better, range 0.5–1.0)
- The optimal threshold point (max Youden) is annotated on the curve

**Youden Index plots:**
- X-axis: log2 FC for each comparison
- Y-axis: `TPR - FPR` (Youden's Index)
- The best point (maximum Youden) is marked with a black diamond
- A vertical dashed line shows the threshold position

**Output details:**
- `ROC_data.xlsx` contains one sheet per comparison:
  - Columns: `Comparison_logFC_Threshold`, `Comparison_logFC_TP`, `Comparison_logFC_FP`, `Comparison_logFC_TP_FP`
- `all_thresholds.xlsx` contains one sheet per version, listing the best threshold per comparison

**Testing checklist:**
1. Run Modules 1–7 first
2. Execute Module 8
3. Confirm console outputs show:
   - SubMito transformation progress (number of localization columns converted)
   - MitoCarta3 sub-localization categories (MIM, Matrix, MOM, IMS)
   - ROC summary (TP/FP counts, AUC values)
   - Selected thresholds
4. Verify `Output/` contains:
   - ROC and Youden PDF plots
   - ROC data and thresholds Excel workbooks
   - CSV with SubMito-transformed data
5. Ensure `Module08_workspace.RData` exists
6. Inspect `roc_results1` structure:
   ```r
   names(roc_results1)  # all versions
   names(roc_results1[[1]])  # should include: roc_objects, roc_dfs, thresholds, data_transformed
   ```
7. Validate SubMito annotations:
   ```r
   unique(data_with_submito$noNorm_Imputed$GO_Localization)
   # Should include: SGs, Matrix, MIM, MOM, IMS, Nuclear, Cytosol, Other, etc.
   ```
8. Examine ROC AUCs:
   ```r
   lapply(roc_results1$noNorm_Imputed$roc_objects, pROC::auc)
   ```
9. Review thresholds:
   ```r
   roc_thresholds1
   ```

**Configuration (in `main_pipeline.R`):**
```r
selected_versions_roc <- c("noNorm_Imputed", "Local_QNorm_Imputed")
roc_annotation_column <- "GO_Localization"
tp_label <- "SGs"
fp_label <- "Matrix"
enable_submito <- TRUE
submito_annotation_columns <- NULL
min_tp <- 0.3
```

**Notes:**
- Module 3 must run first (provides `annotation_references` and MitoCarta data)
- Module 7 must run first (provides `diff_results1` and logFC values)
- SubMito transformation is enabled by default; disable with `enable_submito = FALSE`
- Localization columns are auto-detected when `submito_annotation_columns = NULL`
- ROC requires ≥5 TP and FP samples; otherwise the version is skipped
- Candidate thresholds must have `TP >= 0.3` to ensure enough sensitivity
- Requires `pROC` and `openxlsx`
- Output files are prefixed with `Module08_`
- RData files stay in the working directory; PDFs/XLSXs/CSVs go to `Output/`
- `Matrix` is the default FP label because it represents non-SG mitochondrial matrix proteins
- `direction = "<"` assumes FP logFC values are lower than TP, which suits SG-enrichment analysis

**Technical note on Youden's Index:**
Youden's Index (`J`) is defined as `TPR + Specificity - 1`, or `TPR - FPR`. It ranges from 0 to 1, with higher values indicating a better separation.

---

### Module 9: Background subtraction

**Responsibilities:**
1. Generate two filtering variants (Method A and Method B) in parallel:
   - **Method A** bypasses FDR filtering for specified comparisons (FDR is set to 1 for those comparisons)
   - **Method B applies FDR filtering to every comparison
2. Apply per-`bioGroup` thresholds derived from Module 8 ROC outputs
3. Process `bioGroup`s based on `sampleGroup$Context`:
   - `Experiment`: apply logFC and FDR thresholds
   - `Spatial`: keep the columns, remove rows with all `NA`s (no thresholds)
   - `Control`: skipped entirely
4. Enforce a minimum number of valid LFQ values per protein in catalytic groups
5. Summarize counts, means, and sums per annotation (e.g., `GO_Localization`)
6. Merge all filtered data frames across `bioGroup`s
7. Visualize the filtered results using stacked barplots for protein count and abundance

**Inputs:**
- `Module08_workspace.RData` — includes `diff_results1`, `roc_thresholds1`, `comparison_info`, etc.
- `sampleGroup` — must include the `Context` column (Experiment/Spatial/Control)
- `expr_fdr_df_list` (optional, recommended) — Module 8 output that serves as the filtering base (Gene, expression, annotations, FC/FDR without SubMito columns)
- `data_with_submito` (optional alternative) — Module 8 output used only if `expr_fdr_df_list` is missing

**Outputs:**
- `Module09_workspace.RData` — workspace gains `filtered_data_A`, `filtered_data_B`, `merged_data_A`, `merged_data_B`
- `Output/Module09_{method}_{version}_FilteredData.xlsx` — per-method filtered data with multiple sheets (all `Experiment` `bioGroup`s first, followed by `Spatial` `bioGroup`s; each has a data sheet and a `_Summarise` summary)
- `Output/Module09_{method}_{version}_AfterROC_data_summarise.xlsx` — inspection workbook with a fixed sheet order (Exp data → Spatial data → Exp summaries → Spatial summaries)
- `Output/Module09_{method}_{version}_AfterROC_data_merged.xlsx` — merged table (`AfterROC_merged`)
- `Output/Module09_{method}_{version}_CountPercent_StackBar.pdf` — stacked barplot of protein counts
- `Output/Module09_{method}_{version}_AbundancePercent_StackBar.pdf` — stacked barplot of abundance percentages

**Core function:**
```r
result <- module09_background_subtraction(
  dir_config,
  sampleGroup,
  diff_results1,
  roc_thresholds1,
  comparison_info,
  data_with_submito,
  expr_fdr_df_list,
  selected_versions = c("noNorm_Imputed", "Local_QNorm_Imputed"),
  fdr_threshold = 0.05,
  no_fdr_comparisons = c("K69A1B3_Light_vs_A1B3_Light"),
  use_roc_threshold = TRUE,
  fixed_fc_threshold = NULL,
  min_valid_lfq = 2,
  annotation_column = "GO_Localization",
  plot_all_annotations = FALSE,
  tp_label = "SGs",
  tp_color = "#DB6968"
)

filtered_data_A <- result$filtered_data_A
filtered_data_B <- result$filtered_data_B
merged_data_A <- result$merged_data_A
merged_data_B <- result$merged_data_B
```

**Usage examples:**
1. Standard usage generating both methods with several comparisons exempted from FDR:
```r
result <- module09_background_subtraction(
  dir_config, sampleGroup, diff_results1, roc_thresholds1, comparison_info,
  selected_versions = c("noNorm_Imputed"),
  fdr_threshold = 0.05,
  no_fdr_comparisons = c("K69A1B3_Light_vs_A1B3_Light", "K69C3_Light_vs_C3_Light"),
  use_roc_threshold = TRUE,
  min_valid_lfq = 2,
  annotation_column = "GO_Localization",
  plot_all_annotations = FALSE,
  tp_label = "SGs"
)
```
2. Set `no_fdr_comparisons = NULL` so Method A and Method B are identical
3. Switch to a fixed FC threshold instead of ROC thresholds:
```r
use_roc_threshold = FALSE
fixed_fc_threshold = 2.0
```
4. Display every annotation category in the stacked barplots by setting `plot_all_annotations = TRUE`

**Filtering workflow:**
- Identify all `bioGroup`s from `sampleGroup` and order them (Experiment first, then Spatial; Control is ignored)
- **Experiment groups**: apply logFC and FDR thresholds per comparison (Method A skips FDR for comparisons in `no_fdr_comparisons`, Method B always applies it); require at least `min_valid_lfq` non-NA LFQ columns
- **Spatial groups**: keep Gene, LFQ, and annotation columns; drop rows with all `NA`s without applying thresholds
- **Control groups**: no action
- Summaries are grouped by annotation and include counts, means, sums, count percentages, abundance percentages, and composite metrics such as `MeanSum`

**Stacked barplots:**
- X-axis: `bioGroup`
- Y-axis: counts or abundance percentage (`MeanSum`)
- Fill color: annotation categories (TPs, e.g., SGs, get red `#DB6968`; others follow either a palette or gray when `plot_all_annotations = FALSE`)
- Legend displays annotation names and colors
- Title includes the version, Method, and FDR thresholds; subtitles describe the logFC/FDR thresholds used per `bioGroup`

**Merged data construction:**
- Collect filtered data from every `bioGroup` (excluding `_Summarise` sheets)
- Merge via `reduce(data_list, full_join, by = "Gene")`, retaining Gene, all LFQ columns, and annotation columns

**Method A vs. Method B:**
| Aspect | Method A | Method B |
|---|---|---|
| Purpose | Relax FDR for selected comparisons | Apply FDR to every comparison |
| FDR handling | Selected comparisons skip FDR (FDR=1) | All comparisons use `fdr_threshold` |
| Configuration | Specify `no_fdr_comparisons` | Set `no_fdr_comparisons = NULL` |
| Use cases | Exploratory analyses to avoid missing candidates | Conservative filtering for high confidence |

**Testing checklist:**
1. Finish Modules 1–8
2. Ensure `sampleGroup$Context` is populated
3. Run Module 9
4. Check console output for counts of Experiment/Spatial/Control groups, methods, and per-`bioGroup` results
5. Inspect the `Output/` files described above (filtered data, summaries, merged data, stacked barplots)
6. Verify `Module09_workspace.RData` exists
7. Explore result lists to confirm structure (versions, `bioGroup` sections, summaries)
8. Confirm min logFC and FDR distributions meet expectations
9. Compare Method A vs. Method B counts to understand relaxed FDR effects
10. Ensure list order is Experiment data, Experiment summaries, Spatial data, Spatial summaries

**Configuration snippet (in `main_pipeline.R`):**
```r
selected_versions_bg <- c("noNorm_Imputed", "Local_QNorm_Imputed")
fdr_threshold <- 0.05
no_fdr_comparisons <- c("K69A1B3_Light_vs_A1B3_Light", "K69C3_Light_vs_C3_Light")
use_roc_threshold <- TRUE
fixed_fc_threshold <- NULL
min_valid_lfq <- 2
annotation_column <- "GO_Localization"
plot_all_annotations <- FALSE
tp_label <- "SGs"
tp_color <- "#DB6968"
```

**Notes:**
- Module 8 must run previously (supplies ROC thresholds and comparison metadata)
- Control (Context = `Control`) `bioGroup`s are skipped entirely
- Spatial groups are handled without thresholds; Control samples are ignored
- `no_fdr_comparisons` supports vector inputs; Method A is always generated
- `min_valid_lfq` enforces that catalytic proteins appear in at least `n` valid replicates (default 2)
- Visualization color schemes can be toggled with `plot_all_annotations`
- NP = True Positive (TP) categories such as `SGs` are always highlighted in red when `plot_all_annotations = FALSE`
- Requires `ggplot2`, `dplyr`, and `openxlsx`
- Output files follow the `Module09_{method}_{version}_...` naming pattern

**Technical details:**
- Catalytic filtering uses `rowSums(!is.na(LFQ_cols)) >= min_valid_lfq`
- Spatial groups remove rows with all `NA`s via `na.omit()` without thresholding
- Abundance percentages are computed per LFQ column, normalized, and averaged to yield `MeanSum`
- Titles and subtitles fetch thresholds from `comparison_info` and `roc_thresholds1`

---

### Module 10: Data replacement

**File:** `Module/module10_data_replacement.R`

**Responsibilities:**
1. Replace all non-`NA` cells in the merged AfterROC matrices (`merged_data_A` and `merged_data_B`) with values from a preferred global normalization version (prefers `Global_QNorm_Imputed`, falls back to `Global_MNorm_Imputed`)
2. Keep all `NA`s intact to preserve missing data structure
3. Produce validation reports by sampling a subset of genes and comparing replacements
4. Store check reports inside `Output/Check/`

**Inputs:**
- `Module09_workspace.RData` — contains `merged_data_A` and `merged_data_B`
- `imputed_data_list` — Module 5 results (includes global normalization versions)
- `sampleGroup` — provides LFQ column names
- `selected_versions` — versions to replace

**Outputs:**
- `Module10_workspace.RData` — adds `replaced_data_A` and `replaced_data_B`
- `Output/Module10_{method}_{version}_AfterFirstROC_Intersect.xlsx` — replaced matrices
- Validation files inside `Output/Check/`:
  - `Module10_{method}_{version}_replacement_check.csv`
  - `Module10_{method}_{version}_replacement_summary.txt`

**Core function:**
```r
result <- module10_data_replacement(
  dir_config = dir_config,
  sampleGroup = sampleGroup,
  merged_data_A = merged_data_A,
  merged_data_B = merged_data_B,
  imputed_data_list = imputed_data_list,
  selected_versions = selected_versions,
  prefer_version = "Global_QNorm_Imputed",
  fallback_version = "Global_MNorm_Imputed",
  test_n = 20
)

replaced_data_A <- result$replaced_data_A
replaced_data_B <- result$replaced_data_B
```

**Replacement logic:**
- Align each `merged_data` with the preferred normalization by `Gene`
- Replace every non-`NA` cell with the corresponding value from the global normalization dataset
- Keep `NA` cells untouched

**Workflow:**
1. Determine the reference version (`Global_QNorm_Imputed` unless unavailable, then `Global_MNorm_Imputed`)
2. Create `Output/Check/` for validation artifacts
3. For each method/version pair, iterate over LFQ columns and perform cell-wise replacement while keeping `NA`s
4. Sample up to `test_n` genes and up to three LFQ columns; export `replacement_check.csv` showing `Original`, `Replaced`, `Imputed`, and `CellMatch`
5. Write a summary TXT that reports counts of replaced cells and preserved `NA`s
6. Export final replaced matrices as XLSX files

**Usage examples:**
- Standard workflow using `Global_QNorm_Imputed` as the reference
- Switch to `Global_MNorm_Imputed` if the quantile-normalized version is missing
- Increase `test_n` to probe more genes during validation

**Testing checklist:**
1. Ensure Module 9 produced `Module09_workspace.RData`
2. Confirm Module 5 produced `imputed_data_list`
3. Run Module 10
4. Verify the console logs report chosen reference version, data dimensions, replaced cell counts, and preserved `NA`s
5. Check `Output/Module10_{method}_{version}_AfterFirstROC_Intersect.xlsx` for each method and version
6. Review the `replacement_check.csv` and `replacement_summary.txt` files under `Output/Check/`
7. Confirm `CellMatch` is `TRUE` for all non-`NA` replacements
8. Validate `NA` positions and counts are unchanged after replacement

**Notes:**
- Module 5 must finish first because it provides the global normalized reference tables
- Module 10 operates on merged matrices, not the per-`bioGroup` filtered tables
- The `prefers_version` parameter defaults to `Global_QNorm_Imputed`
- Validation files live in `Output/Check/`
- `CellMatch` comparisons tolerate a small numeric tolerance (e.g., `1e-9`)
- Requires `dplyr` and `openxlsx`
- Output files are prefixed with `Module10_{method}_{version}_...`

**Technical details:**
- Replacement loops over LFQ columns and substitutes values where the original is not `NA`
- Implementation mirrors the original logic in `CleanCode.R` (lines 2303–2361)
- Validation CSV columns include `Gene`, `Sample`, `Original`, `Replaced`, `Imputed`, and `CellMatch`
- Summary TXT reports version, method, replaced cell counts, and NA preservation

---

### Module 11: Second differential analysis

**File:** `Module/module11_diff_analysis2.R`

**Responsibilities:**
1. Run a second limma-based differential expression analysis on the replaced matrices from Module 10
2. Use only samples with `Context` set to `Experiment` or `Spatial` (exclude `Control`)
3. Build comparisons as:
   - **Experiment vs Experiment** (all pairs regardless of `PLtype`)
   - **Experiment vs Spatial** (only between matching `PLtype`s)
4. Summarize logFC and adjusted p-values for every comparison and append annotation columns

**Inputs:**
- `Module10_workspace.RData`
- `replaced_data_A` and `replaced_data_B`
- `sampleGroup` (includes `Context` and `SecondROCgroup`)
- `selected_versions` (default `selected_versions_bg`) controlling which versions to analyze

**Outputs:**
- `Module11_workspace.RData` — adds `FDR_combined_df_list_2nd`, `sample_info_2nd`, `comparisons_list_2nd`, `bioGroups_selected_2nd`, etc.
- `Output/Module11_Raw_FDR_test_list_{version}_{method}.xlsx` — per-comparison `topTable` exports
- `Output/Module11_FC_FDR_2nd_combined.xlsx` — aggregated logFC/adj.P.Val table with annotations across all versions/methods

**Key data structures:**
- `FDR_combined_df_list_2nd`: keyed by `{version}_{method}` (e.g., `noNorm_Imputed_A`)
- `sample_info_2nd`: the filtered sample metadata for the second analysis
- `comparisons_list_2nd`: list of comparison names
- `bioGroups_selected_2nd`: the `bioGroup`s involved in the analysis

**Workflow:**
1. Select samples labeled `Experiment` or `Spatial`
2. Use `SecondROCgroup` and `Context` to determine Exp-vs-Exp and Exp-vs-Spatial comparisons
3. Fit limma models (`lmFit`, `makeContrasts`, `eBayes`) and call `topTable(..., adjust.method = "BH")`
4. Merge the results for all comparisons into a single wide table and add annotation columns at the end

**Usage example:**
- Example sample set:
  - `K69A1B3_Light` (Experiment, SecondROCgroup = A)
  - `K69C3_Light` (Experiment, B)
  - `C3_H2O2` (Experiment, C)
  - `K20_Light` (Spatial, A&B)
  - `K73_H2O2` (Spatial)
- Formed comparisons (six pairs):
  1. `K69A1B3_Light_vs_K69C3_Light`
  2. `K69A1B3_Light_vs_C3_H2O2`
  3. `K69C3_Light_vs_C3_H2O2`
  4. `K69A1B3_Light_vs_K20_Light`
  5. `K69C3_Light_vs_K20_Light`
  6. `C3_H2O2_vs_K73_H2O2`

**Testing:**
- The log of Module 11 should show:
  - Four versions (`noNorm_Imputed` and `Local_QNorm_Imputed`, each with Methods A/B)
  - Explicit confirmation of sample selection (15 Experiment/Spatial samples)
  - Six constructed comparisons
  - Each version and method exporting one raw `topTable` and contributing to the combined workbook

**Configuration (in `main_pipeline.R`):**
```r
result <- module11_diff_analysis2(
  dir_config = dir_config,
  sampleGroup = sampleGroup,
  replaced_data_A = replaced_data_A,
  replaced_data_B = replaced_data_B,
  selected_versions = selected_versions_bg
)
```

**Notes:**
- Comparisons involving Spatial controls only occur when the `PLtype` matches between Experiment and Spatial groups
- Output Excel files may contain long sheet names; they are truncated to 31 characters automatically

---

### Module 12: Second ROC analysis

**File:** `Module/module12_second_roc.R`

**Responsibilities:**
1. Run ROC analysis for every version produced by Module 11 using the second-round differential data
2. Use `GO_Localization` with `SGs` as true positives and `Cytosol` as false positives by default
3. Determine optimal log2FC thresholds for six comparisons (require TPR ≥ 0.3, otherwise set the threshold to 0)
4. Build `Expr_FDR_df_list_2nd` by left-joining the Method A/B expression matrices with the second diff results

**Inputs:**
- `FDR_combined_df_list_2nd`
- `expr_data_list_2nd` (Method A/B replaced data combined with `_A` and `_B` suffixes)
- Optional `sample_columns` to restrict expression matrices to Experiment/Spatial samples (defaults to `sample_info_2nd$SampleName`)
- `dir_config$output`
- Optional parameters: `desired_order`, `annotation_column`, `comparison_cols`

**Outputs:**
- `Output/Module12_Step16_{version}_{FP}_{TP}_ROCdata.xlsx`
- `Output/Module12_Step16_1_{version}_GO_CytosolROC.pdf`
- `Output/Module12_Step16_1_{version}_Youden_Index_Plots_BaseR.pdf`
- `Output/Module12_Step16_all_desired_thresholds_2nd.xlsx` (one sheet per version detailing each comparison, its logFC column, annotations, TP/FP labels, and threshold)
- `Output/Module12_Step16_Expr_FDR_df_list_2nd.xlsx`
- `Module12_workspace.RData`

**Invocation example:**
```r
result <- module12_second_roc(
  dir_config = dir_config,
  FDR_combined_df_list_2nd = FDR_combined_df_list_2nd,
  expr_data_list = expr_data_list_2nd,
  desired_order = if (length(second_roc_order) > 0) second_roc_order else names(FDR_combined_df_list_2nd)
)
```

**Notes:**
- The main pipeline renames versions via `stringr::str_replace("_Imputed", "_New")` for consistency with the legacy `CleanCode` structure
- `expr_data_list_2nd` merges `replaced_data_A` and `replaced_data_B` with `_A`/`_B` suffixes for filtering downstream
- All outputs use the `Module12_` prefix and retain Step 16 identifiers for traceability

---

### Module 13: SubSG annotation

**File:** `Module/module13_subsg_annotation.R`

**Responsibilities:**
1. Append SubSG annotations to `Expr_FDR_df_list_2nd` following the logic in `CleanCode.R` (lines 2708–2742)
2. Overwrite the `MultiBait_Localization` column by default (creates it if missing after the last `_Localization` column)
3. Generate nine classification categories combining HaloMap, HPA, and MitoCarta annotations (e.g., `Nuclear&Cytosol&SGs`, `Nuclear&SGs`, `Cytosol&SGs`)
4. Export `Output/Module13_{version}_SubSGs.csv` and return `Expr_FDR_df_list_2nd_SubSGs`
5. Provide `ForStep16` subsets that align with the legacy `CleanCode` `ForStep16` object (configurable via `forstep16_versions`)

**Inputs:**
- `expr_fdr_df_list_2nd` (Module 12 output)
- `annotation_references` (Module 3 output providing HaloMap/HPA/MitoCarta data)
- Optional parameters: `target_column`, `levels_order`, `forstep16_versions`, `output_prefix`

**Outputs:**
- `Expr_FDR_df_list_2nd_SubSGs`
- `ForStep16` (used by later modules that compare to Spatial controls)
- `Output/Module13_{version}_SubSGs.csv`
- `Module13_workspace.RData`

**Usage example:**
```r
result <- module13_subsg_annotation(
  dir_config = dir_config,
  expr_fdr_df_list_2nd = Expr_FDR_df_list_2nd,
  annotation_references = annotation_references,
  target_column = "MultiBait_Localization",
  forstep16_versions = c("noMBR_New_A", "noMBR_QNorm_New_A", "noMBR_Local_QNorm_New_A")
)
Expr_FDR_df_list_2nd_SubSGs <- result$Expr_FDR_df_list_2nd_SubSGs
ForStep16 <- result$ForStep16

---

### Module 14: Volcano plots

**File:** `Module/module14_volcano_plots.R`

**Responsibilities:**
1. Inspect `Expr_FDR_df_list_2nd_SubSGs` to list available versions, annotation columns (`*_Localization`), and their unique categories
2. Detect paired `_logFC` and `_adj.P.Val` columns to enumerate comparisons, then categorize them as `Exp_vs_Exp` or `Exp_vs_Spatial` using `comparisons_list` and `bioGroup_info` from Module 11
3. Allow filtering by `comparison_categories` (e.g., only `Exp_vs_Exp`)
4. Generate PDFs for each combination of version, comparison, annotation column, and label mode using custom color maps or significance thresholds; `label_mode` can request both labeled and unlabeled plots
5. Leave the source data unchanged

**Inputs:**
- `expr_fdr_df_list_2nd_subsgs`
- `dir_config$output`
- Parameters such as:
  - `versions` (default: all)
  - `annotation_column` for coloring (e.g., `GO_Localization`)
  - `annotation_color_map` (named colors per annotation value)
  - `use_threshold_colors` (overrides annotation colors when `TRUE`)
  - `logfc_threshold`, `fdr_threshold` for significance coloring
  - `threshold_color_above`, `threshold_color_below`
  - `label_mode` (`"with"`, `"without"`, or both)
  - `label_annotations` (which annotation categories may be labeled)
  - `comparison_sets` (custom combinations of logFC/FDR columns, axis ranges, output names)
  - `comparison_categories` (e.g., `c("Exp_vs_Exp", "Exp_vs_Spatial")`) to constrain plotted comparisons

**Outputs:**
- `Output/Module14_Step20_{annotation}_{comparison}_{labelMode}.pdf` (one PDF per `comparison_set × label_mode`)
- `Output/Module14_Step20_VolcanoSource.xlsx` (contains the source data used for each version/comparison with logFC, FDR, annotations, and threshold flags)
- `Module14_workspace.RData`
- Returned list containing `pdf_files` (dictionary-style metadata for reporting)

**Default invocation (as configured in `main_pipeline.R`):**
```r
volcano_result <- module14_volcano_plots(
  dir_config = dir_config,
  expr_fdr_df_list_2nd_subsgs = Expr_FDR_df_list_2nd_SubSGs,
  versions = volcano_versions,
  annotation_column = volcano_annotation_column,
  annotation_color_map = volcano_annotation_color_map,
  use_threshold_colors = volcano_use_threshold_colors,
  logfc_threshold = volcano_logfc_threshold,
  fdr_threshold = volcano_fdr_threshold,
  threshold_color_above = volcano_threshold_color_above,
  threshold_color_below = volcano_threshold_color_below,
  label_mode = volcano_label_mode,
  label_annotations = volcano_label_annotations,
  comparison_sets = volcano_comparison_sets,
  comparison_categories = volcano_comparison_categories
)
```

---

## File naming conventions summary

### Workspace files
- **Environment data**: `ModuleXX_workspace.RData` keeps accumulating the environment state
- **Grouping tables**:
  - `Module02_sampleGroup_template.csv` is the template the user fills
  - `Module02_sampleGroup.csv` is the validated table generated by the pipeline

### Output directory files
- **CSV exports** follow `ModuleXX_<description>.csv`
- **PDF exports** follow `ModuleXX_<description>.pdf`

### Module directory files
- **Module code** is stored as `moduleXX_<description>.R`


## Configuration interface summary

### Data import configuration (Module 2)
Edit the pattern in `main_pipeline.R`:
```r
data_config <- list(
  file_pattern = "_matrix.*\.tsv$"
)
```

### Annotation configuration (Module 3)
Add custom annotations as needed:
```r
custom_annotations <- list(
  list(
    column_name = "Custom_Localization",
    TP_source = "GO_SGs",
    TP_column = "Gene",
    TP_label = "SGs"
  )
)
```

### Normalization configuration (Module 4)
Choose which normalization methods to run:
```r
norm_types <- c("noNorm", "Global_QNorm", "Global_MNorm", "Local_QNorm", "Local_MNorm")
```
Alternatively:
```r
norm_types <- c("noNorm", "Global_QNorm")
```

### Imputation configuration (Module 5)
Control Perseus filling and the RNG seed:
```r
impute_cat_mean <- FALSE
random_seed <- 123
# Enable Cat-group imputation if desired
impute_cat_mean <- TRUE
```

### Heatmap system configuration (Module 6)
Set versions, heatmap types, and styles:
```r
selected_versions <- c("noNorm_Imputed", "Local_QNorm_Imputed")
heatmap_types <- c("all", "correlation", "by_localization")
correlation_config <- list(
  corr_min = 0.8,
  corr_max = 1,
  corr_center = 0.9,
  col_low = "#4D97CD",
  col_center = "white",
  col_high = "#DB6968",
  exclude_context = NULL,
  exclude_pltype = NULL,
  exclude_catalytic = c("NoCat"),
  include_biogroups = NULL
)
localization_columns <- NULL
color_params <- list(
  custom_min = -4,
  custom_max = 4,
  custom_center = 0,
  col_low = "#4D97CD",
  col_center = "white",
  col_high = "#DB6968"
)
```

### Differential analysis configuration (Module 7)
```r
selected_versions_diff <- c("noNorm_Imputed", "Local_QNorm_Imputed")
```
Ensure `sampleGroup` includes `FirstROCgroup`, `Context`, and `bioGroup`.

### ROC analysis configuration (Module 8)
```r
selected_versions_roc <- c("noNorm_Imputed", "Local_QNorm_Imputed")
roc_annotation_column <- "GO_Localization"
tp_label <- "SGs"
fp_label <- "Matrix"
enable_submito <- TRUE
submito_annotation_columns <- NULL
min_tp <- 0.3
```
Customize these parameters when you want to change the TP/FP sets or disable SubMito conversion.

### Background subtraction configuration (Module 9)
```r
selected_versions_bg <- c("noNorm_Imputed", "Local_QNorm_Imputed")
fdr_threshold <- 0.05
no_fdr_comparisons <- c("K69A1B3_Light_vs_A1B3_Light", "K69C3_Light_vs_C3_Light")
use_roc_threshold <- TRUE
fixed_fc_threshold <- NULL
min_valid_lfq <- 2
annotation_column <- "GO_Localization"
plot_all_annotations <- FALSE
tp_label <- "SGs"
tp_color <- "#DB6968"
```
Common tweaks:
```r
correlation_config$exclude_catalytic <- c("NoCat")
correlation_config$exclude_context <- c("Control")
correlation_config$include_biogroups <- c("K69A1B3_Light", "K69C3_Light", "C3_H2O2")
color_params <- list(custom_min = -3, custom_max = 3, custom_center = 0,
                     col_low = "#0000FF", col_center = "#FFFFFF", col_high = "#FF0000")
no_fdr_comparisons <- NULL
use_roc_threshold <- FALSE
fixed_fc_threshold <- 2.0
no_fdr_comparisons <- c("K69A1B3_Light_vs_A1B3_Light", "K69C3_Light_vs_C3_Light", "C3_H2O2_vs_noH2O2")
```

### Module 12: Second ROC analysis
See Module 12 translation above for its configuration details.

### Module 13: SubSG annotation
Use the sample invocation in the Module 13 section to specify `target_column` and `forstep16_versions`.

### Module 14: Volcano plots
Use the default invocation in the Module 14 section and adjust plotting parameters (`versions`, `annotation_column`, `comparison_sets`, etc.) as needed.
